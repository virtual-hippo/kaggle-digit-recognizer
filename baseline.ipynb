{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer\n",
    "\n",
    "チュートリアル用コンペ\n",
    "\n",
    "https://www.kaggle.com/competitions/digit-recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# import joblib\n",
    "import pickle\n",
    "\n",
    "# import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# models\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "#from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class Config:\n",
    "    VER = 1\n",
    "    AUTHOR = \"virtual-hippo\"\n",
    "    COMPETITION = \"Digit Recognizer\"\n",
    "    DATA_PATH = Path(\"./input\")\n",
    "    OOF_DATA_PATH = Path(\"./oof\")\n",
    "    MODEL_DATA_PATH = Path(\"./model\")\n",
    "    SUB_DATA_PATH = Path(\"./submit\")\n",
    "\n",
    "    epochs = 50\n",
    "    batch_size = 128\n",
    "    seed = 42\n",
    "    verbose = 25\n",
    "    n_folds = 5\n",
    "    target_col = \"label\"\n",
    "    metric = \"f1_score\"\n",
    "    early_stopping_round = 200\n",
    "    classification_lgb_params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 10,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"seed\": seed,\n",
    "    }\n",
    "    model_weight_dict = {\"lightgbm\": 0.50}\n",
    "    \n",
    "    def features():\n",
    "        return [f\"pixel{i}\"  for i in range(0,784)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの読み込み関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data():\n",
    "    return pd.read_csv(Config.DATA_PATH.joinpath(Path('train.csv')))\n",
    "\n",
    "def read_test_data():\n",
    "    return pd.read_csv(Config.DATA_PATH.joinpath(Path('test.csv')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocessing(input_df: pd.DataFrame, preprocessors) -> pd.DataFrame:\n",
    "    def normarization(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        input_df[Config.features()] = input_df[Config.features()].astype('float32').apply(lambda x: x/255)\n",
    "        return input_df\n",
    "    \n",
    "    def make_features(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        output_df = input_df.copy()\n",
    "        # いろいろ特徴量作成を追加する\n",
    "        for f in preprocessors:\n",
    "            output_df = f(output_df)\n",
    "        return output_df\n",
    "    \n",
    "    output_df = input_df.copy()\n",
    "    output_df = normarization(output_df)\n",
    "    output_df = make_features(output_df)\n",
    "\n",
    "    return output_df\n",
    "\n",
    "train_df = read_train_data()\n",
    "train_df = preprocessing(train_df, [])\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        model = Sequential()\n",
    "        #model.add(Conv2D(filters=32, kernel_size=(3, 3),input_shape=(28,28,1)))\n",
    "        model.add(Activation('relu'))\n",
    "        #model.add(Conv2D(filters=64, kernel_size=(3, 3)))\n",
    "        model.add(Activation('relu'))\n",
    "        #model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(10))\n",
    "        model.add(Activation('softmax'))\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "        self.model = model\n",
    "\n",
    "    def fit(self, x_train, y_train,x_valid,y_valid):\n",
    "        self.model.fit(x_train, y_train,\n",
    "          batch_size=Config.batch_size,\n",
    "          epochs=Config.epochs,\n",
    "          verbose=Config.verbose,\n",
    "          validation_data=(x_valid, y_valid))\n",
    "        \n",
    "        # Predict validation\n",
    "        valid_pred = self.model.predict(x_valid)\n",
    "        return self.model, valid_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn():\n",
    "    kfold = StratifiedKFold(n_splits=Config.n_folds, shuffle=True, random_state=Config.seed)\n",
    "    \n",
    "\n",
    "    for fold, (train_index, valid_index) in enumerate(kfold.split(train_df[Config.features()], train_df[Config.target_col])):\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"training fold {fold+1}\")\n",
    "\n",
    "        model = Model()\n",
    "        x_train = train_df[Config.features()].iloc[train_index].to_numpy()\n",
    "        y_train = train_df[Config.target_col].iloc[train_index].to_numpy()\n",
    "\n",
    "        x_valid = train_df[Config.features()].iloc[valid_index].to_numpy()\n",
    "        y_valid = train_df[Config.target_col].iloc[valid_index].to_numpy()\n",
    "\n",
    "        # x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "        # x_valid = x_valid.reshape(-1, 28, 28, 1)\n",
    "\n",
    "        \n",
    "        y_train = to_categorical(y_train)\n",
    "        y_valid = to_categorical(y_valid)\n",
    "\n",
    "        model, valid_pred = model.fit(np.array(x_train), np.array(y_train), np.array(x_valid), np.array(y_valid))\n",
    "\n",
    "        pickle.dump(\n",
    "            model,\n",
    "            open(\n",
    "                Config.MODEL_DATA_PATH.joinpath(Path(f\"fold{fold + 1}_seed{Config.seed}_ver{Config.VER}.pkl\")),\n",
    "                \"wb\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "        gc.collect()\n",
    "\n",
    "learn()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    test_df = read_test_data()\n",
    "    test_df = preprocessing(test_df, [])\n",
    "    \n",
    "    x_test = test_df[Config.features()].to_numpy()\n",
    "\n",
    "    \n",
    "    print(x_test.shape)\n",
    "    print(x_test)\n",
    "\n",
    "    df = pd.DataFrame({'ImageId': range(1, len(x_test) + 1)})\n",
    "\n",
    "    for fold in range(Config.n_folds):\n",
    "        model = pickle.load(\n",
    "            open(\n",
    "                Config.MODEL_DATA_PATH.joinpath(Path(f\"fold{fold + 1}_seed{Config.seed}_ver{Config.VER}.pkl\")),\n",
    "                \"rb\",\n",
    "            )\n",
    "        )\n",
    "        # Predict\n",
    "        pred = np.argmax(model.predict(x_test), axis=1)\n",
    "        df[f\"fold_{fold}\"] = pred\n",
    "\n",
    "        print(pred.shape)\n",
    "        print(pred)\n",
    "    \n",
    "    return df\n",
    "\n",
    "pred_df = predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_path():\n",
    "    now = datetime.datetime.now(tz=ZoneInfo(\"Asia/Tokyo\"))\n",
    "    now_str = f\"{now.strftime('%Y%m%d_%H%M%S')}\"\n",
    "    filename = f\"{now_str}_seed{Config.seed}_ver{Config.VER}_{Config.AUTHOR}_submission.csv\"\n",
    "    return Config.SUB_DATA_PATH.joinpath(Path(filename))\n",
    "\n",
    "out_df = pred_df.copy()\n",
    "out_df[\"Label\"] = out_df.iloc[:, 1:6].apply(lambda row: sp.stats.mode(row, keepdims=True).mode[0], axis=1)\n",
    "out_df[[\"ImageId\", \"Label\"]].to_csv(\n",
    "    output_path(),\n",
    "    header=True,\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-digit-recognizer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
